{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7dbab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12e3e338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.95 ðŸš€ Python-3.8.9 torch-2.0.1 CPU\n",
      "Setup complete âœ… (8 CPUs, 8.0 GB RAM, 186.6/228.3 GB disk)\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-seg.pt to yolov8l-seg.pt...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88.1M/88.1M [00:03<00:00, 23.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRASPING] - Using N=50 and tol=5\n"
     ]
    }
   ],
   "source": [
    "from src.internal.sumba import Sumba\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open('imgs/d.jpeg')\n",
    "sumba = Sumba(\n",
    "    detector_id=\"yolov8\",\n",
    "    detector_th=0.05,\n",
    "    detector_max_object_size=0.1,\n",
    "    segmentator_id=\"yolov8\",\n",
    "    segmentator_min_mask_size=0.3,\n",
    "    grasping_N=50,\n",
    "    grasping_tol=5,\n",
    "    show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "040bd36c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************************************************\n",
      "**************** STARTING OBJECT RECO PIPELINE ****************\n",
      "***************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 cup, 1 knife, 1 apple, 1 dining table, 690.1ms\n",
      "Speed: 8.2ms preprocess, 690.1ms inference, 16.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- REMOVED OBJECT --------\n",
      "(<PIL.Image.Image image mode=RGB size=1271x693 at 0x28FEB6E20>, [6, 0, 1277, 693], 'dining table', 0.15451081097126007)\n",
      "----------- REMOVED OBJECT --------\n",
      "(<PIL.Image.Image image mode=RGB size=668x141 at 0x28FEB6610>, [4, 111, 672, 252], 'knife', 0.14787721633911133)\n",
      "\n",
      "--- New Object Detected ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 orange, 1 cake, 1 dining table, 759.9ms\n",
      "Speed: 2.0ms preprocess, 759.9ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=110x113 at 0x28FEF2F70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original value: [642, 194, 752, 307]\n",
      "Best Grasping value: [20, 319, 626, 320]\n",
      "Final absolut grasp: (645.4375, 250.3234375, 749.59375, 250.5)\n",
      "\n",
      "--- New Object Detected ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 toilet, 623.0ms\n",
      "Speed: 2.4ms preprocess, 623.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=145x104 at 0x28FEB6400>\n",
      "Original value: [990, 331, 1135, 435]\n",
      "Best Grasping value: [349, 21, 313, 444]\n",
      "Final absolut grasp: (1069.0703125, 335.55, 1060.9140625, 427.2)\n"
     ]
    }
   ],
   "source": [
    "detector_one_object = False\n",
    "results = sumba.run_pipeline(image, detector_one_object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcd56d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cup', (1071.125, 335.55, 1062.684375, 428.5), [989, 331, 1135, 435]),\n",
       " ('orange',\n",
       "  (645.4375, 250.146875, 749.59375, 250.3234375),\n",
       "  [642, 194, 752, 307]),\n",
       " ('suitcase',\n",
       "  (705.1792763157895, 40.54375, 798.7401315789474, 115.62343750000001),\n",
       "  [683, 1, 838, 172]),\n",
       " ('train',\n",
       "  (503.5578125, 148.54166666666666, 550.7453125, 215.36111111111111),\n",
       "  [450, 111, 601, 247])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0da25c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
