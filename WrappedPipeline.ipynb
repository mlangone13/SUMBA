{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7dbab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12e3e338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.95 ðŸš€ Python-3.8.9 torch-2.0.1 CPU\n",
      "Setup complete âœ… (8 CPUs, 8.0 GB RAM, 184.5/228.3 GB disk)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRASPING] - Using N=50 and tol=5\n"
     ]
    }
   ],
   "source": [
    "from src.internal.sumba import Sumba\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open('imgs/e.jpeg')\n",
    "sumba = Sumba(\n",
    "    detector_id=\"yolov8\",\n",
    "    detector_th=0.05,\n",
    "    detector_max_object_size=0.1,\n",
    "    segmentator_id=\"yolov8\",\n",
    "    segmentator_min_mask_size=0.3,\n",
    "    grasping_N=50,\n",
    "    grasping_tol=5,\n",
    "    show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "040bd36c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************************************************\n",
      "**************** STARTING OBJECT RECO PIPELINE ****************\n",
      "***************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 cup, 1 spoon, 2 bananas, 2 apples, 728.1ms\n",
      "Speed: 2.6ms preprocess, 728.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- New Object Detected ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 banana, 653.9ms\n",
      "Speed: 1.6ms preprocess, 653.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=702x403 at 0x28F5712E0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original value: [460, 1396, 1162, 1799]\n",
      "Best Grasping value: [373, 179, 442, 307]\n",
      "Final absolut grasp: (869.1343750000001, 1583.8567708333333, 944.81875, 1718.1901041666667)\n",
      "\n",
      "--- New Object Detected ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 apple, 1056.7ms\n",
      "Speed: 3.4ms preprocess, 1056.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=297x283 at 0x174712550>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original value: [280, 1142, 577, 1425]\n",
      "Best Grasping value: [302, 24, 339, 614]\n",
      "Final absolut grasp: (420.146875, 1152.6125, 437.3171875, 1413.503125)\n",
      "\n",
      "--- New Object Detected ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 cups, 1 spoon, 1 bowl, 1094.7ms\n",
      "Speed: 3.3ms preprocess, 1094.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=354x337 at 0x174712F70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original value: [958, 256, 1312, 593]\n",
      "Best Grasping value: [79, 269, 266, 293]\n",
      "Final absolut grasp: (1001.696875, 397.64531250000005, 1105.13125, 410.2828125)\n",
      "\n",
      "--- New Object Detected ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 bowl, 1 orange, 1130.8ms\n",
      "Speed: 3.0ms preprocess, 1130.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=292x302 at 0x1747607C0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original value: [817, 862, 1109, 1164]\n",
      "Best Grasping value: [60, 146, 532, 490]\n",
      "Final absolut grasp: (844.375, 930.89375, 1059.725, 1093.21875)\n",
      "\n",
      "--- New Object Detected ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 2 cups, 2 spoons, 1 bowl, 1 dining table, 593.2ms\n",
      "Speed: 2.4ms preprocess, 593.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=349x190 at 0x1747BF070>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original value: [1061, 366, 1410, 556]\n",
      "Best Grasping value: [351, 154, 315, 216]\n",
      "Final absolut grasp: (1252.4046875, 449.125, 1232.7734375, 482.5909090909091)\n",
      "\n",
      "--- New Object Detected ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x512 2 knifes, 1 spoon, 1 banana, 1 apple, 1097.8ms\n",
      "Speed: 3.3ms preprocess, 1097.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=298x388 at 0x174760340>\n",
      "Original value: [341, 486, 639, 874]\n",
      "Best Grasping value: [439, 284, 33, 484]\n",
      "Final absolut grasp: (596.51171875, 658.175, 360.20703125, 779.425)\n"
     ]
    }
   ],
   "source": [
    "detector_one_object = False\n",
    "results = sumba.run_pipeline(image, detector_one_object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4eac3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cup', (1071.125, 335.55, 1062.684375, 428.5), [989, 331, 1135, 435]),\n",
       " ('orange',\n",
       "  (645.4375, 250.146875, 749.59375, 250.3234375),\n",
       "  [642, 194, 752, 307]),\n",
       " ('suitcase',\n",
       "  (705.1792763157895, 40.54375, 798.7401315789474, 115.62343750000001),\n",
       "  [683, 1, 838, 172]),\n",
       " ('train',\n",
       "  (503.5578125, 148.54166666666666, 550.7453125, 215.36111111111111),\n",
       "  [450, 111, 601, 247])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ba604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
